{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3830035-4c93-436d-aa9e-60885ce55d31",
   "metadata": {},
   "source": [
    "# Inteligentnta wyszukiwarka\n",
    "\n",
    "W pierwszym przypadku użycia wykorzystamy wektorową bazę danych do stworzenia inteligentnej wyszukiwarki tekstowej. Nie będzie ona działać na wyszukiwaniu podobnych ciągów znaków,\n",
    "a zamiast tego będzie opierać się na wektorowej reprezentacji tekstu. Mocno upraszczając - z każdego tekstu da się stworzyć wektor, który reprezentuje użyte\n",
    "w tekście słowa. Wektor ten, umieszczony w wielowymiarowej przestrzeni, reprezentuje znaczenie tekstu.\n",
    "\n",
    "Poniższe komendy instalują bilbiotekę *Sentence Transformers* ([sbert.net](https://www.sbert.net/)), która posiada wbudowane modele potrafiące przekształcać tekst na wektor.\n",
    "Moglibyśmy po prostu wykonać `pip install sentence-transformers`, ale ta komenda pobrałaby wszystkie zależności, w tym możliwość uruchamiania transformerów na GPU, czego nie potrzebujemy\n",
    "w trakcie laboratorium. Dzięki pominięciu tych zależności oszczędzimy pobieranie około 2 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a78fd02-400b-49b1-821d-7c0d375efd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.5.1%2Bcpu-cp312-cp312-linux_x86_64.whl (174.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.20.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /var/home/student/.local/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.12/site-packages (from torch) (69.0.3)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib64/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: sympy, filelock, torch, torchvision\n",
      "Successfully installed filelock-3.13.1 sympy-1.13.1 torch-2.5.1+cpu torchvision-0.20.1+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib64/python3.12/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.12/site-packages (1.11.3)\n",
      "Requirement already satisfied: nltk in /usr/lib/python3.12/site-packages (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /var/home/student/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/lib64/python3.12/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/lib/python3.12/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: cloudpickle>=2.2.0 in /usr/lib/python3.12/site-packages (from joblib>=1.2.0->scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.12/site-packages (from requests->transformers) (1.26.20)\n",
      "Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.27.1 safetensors-0.5.2 sentencepiece-0.2.0 tokenizers-0.21.0 transformers-4.48.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading sentence_transformers-3.4.0-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install transformers tqdm numpy scikit-learn scipy nltk sentencepiece\n",
    "%pip install --no-deps sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b0d6d-6aac-4852-b317-563c5b4b434a",
   "metadata": {},
   "source": [
    "Od teraz możemy używać transformera, by przekształcić dowolny tekst w wektor. Użyjemy do tego wytrenowanego modelu \n",
    "[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66522a3a-f536-42b8-bc6d-df1adc5ab57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-5.25917932e-02,  1.18866071e-01, -2.19975654e-02,  1.13960300e-02,\n",
       "       -1.04046628e-01, -2.54100226e-02,  7.86777958e-03,  2.90198922e-02,\n",
       "       -3.60894129e-02, -2.05658041e-02, -1.12653812e-02,  2.12511420e-02,\n",
       "       -1.00599453e-02,  3.80982272e-02, -2.99162026e-02, -2.13984530e-02,\n",
       "       -4.74220403e-02,  8.73931199e-02, -5.98045550e-02, -1.41044836e-02,\n",
       "       -3.67920520e-03, -2.14178562e-02,  1.17069989e-01,  1.49915814e-02,\n",
       "       -1.57131720e-02, -4.93872985e-02,  2.56396998e-02,  7.85534531e-02,\n",
       "        3.94085608e-02, -1.84973404e-02, -4.33945321e-02,  4.62529510e-02,\n",
       "        4.40992303e-02, -6.88395798e-02,  5.51727526e-02, -4.77130376e-02,\n",
       "       -1.38131222e-02, -6.33973554e-02, -4.98714931e-02,  4.12313081e-02,\n",
       "       -4.18453403e-02, -4.09811549e-03, -6.12722449e-02,  4.84996960e-02,\n",
       "       -3.21517102e-02,  2.92591024e-02, -5.57255857e-02,  1.41166588e-02,\n",
       "       -7.48583600e-02,  3.48361954e-02, -1.57355085e-01, -5.03571965e-02,\n",
       "        4.06579338e-02, -7.42001683e-02, -5.60480868e-03, -1.69472862e-02,\n",
       "        3.21963094e-02,  1.02220245e-01, -3.20663638e-02, -4.55555990e-02,\n",
       "        5.19057550e-02,  7.48647237e-03, -1.01650141e-01,  2.83872057e-02,\n",
       "        2.99142320e-02, -5.05028218e-02,  6.86445236e-02,  6.40389919e-02,\n",
       "       -6.72728345e-02, -6.61730999e-03,  1.82581376e-02, -1.44200280e-01,\n",
       "       -3.09812054e-02,  6.75096810e-02, -9.02002975e-02, -3.66966762e-02,\n",
       "        3.48244868e-02, -8.09783116e-02,  3.85214537e-02, -1.85777282e-03,\n",
       "        5.98845780e-02,  8.52197129e-03, -7.35523775e-02, -3.32330018e-02,\n",
       "        2.11508060e-03,  1.84478592e-02, -7.53666386e-02,  9.40620080e-02,\n",
       "        3.19362506e-02,  5.03574051e-02,  7.99980201e-03,  3.81012703e-03,\n",
       "       -8.48370865e-02, -8.18580622e-04, -4.65745740e-02,  6.46142140e-02,\n",
       "        4.97751832e-02,  5.15219308e-02,  1.98788326e-02,  5.26501238e-02,\n",
       "        6.87299222e-02,  3.28169428e-02,  7.03580901e-02,  3.42238247e-02,\n",
       "        1.88638382e-02, -3.36420275e-02,  7.30838776e-02, -8.79944884e-04,\n",
       "       -2.87553836e-02,  3.51566486e-02, -5.28513081e-02, -9.30615664e-02,\n",
       "       -3.70056480e-02, -1.09549992e-01, -3.61592546e-02, -6.20280579e-02,\n",
       "        7.00107887e-02,  4.18627113e-02, -1.76554937e-02, -5.89452498e-03,\n",
       "       -7.20310677e-03,  4.39953903e-04,  8.66148993e-03, -3.33708874e-03,\n",
       "        5.98106049e-02,  1.33991744e-02,  1.52635835e-02,  9.08252543e-33,\n",
       "       -3.72082507e-03, -3.96852307e-02, -4.14057821e-02,  5.25138937e-02,\n",
       "       -1.61435492e-02,  3.95890232e-03, -2.46947110e-02, -1.36969343e-03,\n",
       "       -9.30313021e-02, -1.33203240e-02, -5.66565664e-03, -2.19621807e-02,\n",
       "        4.52984944e-02, -2.23740656e-02, -5.16614877e-02, -1.44488318e-02,\n",
       "        5.03419824e-02, -4.00240161e-02, -4.23516631e-02,  1.10034026e-01,\n",
       "        3.01135071e-02,  3.95743512e-02,  3.19688511e-03,  7.90060963e-03,\n",
       "       -3.84082757e-02, -5.43204397e-02, -4.34719473e-02,  7.64297834e-03,\n",
       "       -8.33888203e-02,  5.53707480e-02,  8.85694548e-02, -6.51069954e-02,\n",
       "       -1.25550091e-01, -5.94541691e-02, -3.08076795e-02, -3.69668268e-02,\n",
       "       -5.28804846e-02, -3.53060476e-02,  2.93422490e-02, -5.53117022e-02,\n",
       "        2.37128437e-02, -7.09192157e-02, -1.31015452e-02,  7.89117217e-02,\n",
       "        3.96597274e-02,  5.43391295e-02, -7.07815960e-02,  5.35546616e-03,\n",
       "        7.38129094e-02, -5.15888818e-02,  3.18362564e-02, -2.63283141e-02,\n",
       "       -1.25374421e-01,  6.73962804e-03, -4.69197407e-02,  5.25843240e-02,\n",
       "        2.39951201e-02,  6.44222721e-02,  4.53237072e-02,  1.38207921e-04,\n",
       "       -9.87092592e-03,  3.72249931e-02, -5.78409759e-03, -8.81955959e-03,\n",
       "        4.07531783e-02, -1.50478274e-01, -2.25005671e-02,  2.98877805e-02,\n",
       "        2.29990426e-02, -3.97475511e-02, -7.36100134e-03, -1.17152847e-01,\n",
       "        6.42339513e-02,  6.40160516e-02, -4.63956818e-02,  2.00965069e-02,\n",
       "       -6.42644474e-03, -4.87033539e-02, -4.12514396e-02, -4.01831418e-03,\n",
       "       -5.75435534e-02, -4.41971142e-03,  2.69966219e-02, -8.91945604e-03,\n",
       "        4.70136777e-02,  3.09454035e-02,  3.48135531e-02, -2.30365358e-02,\n",
       "        1.19207548e-02,  2.97949985e-02, -5.25470218e-03, -1.00234346e-02,\n",
       "        9.91753936e-02, -4.21899371e-02,  4.46720496e-02, -9.26428404e-33,\n",
       "        4.87520769e-02,  5.53307272e-02, -4.17562053e-02, -2.09028600e-03,\n",
       "       -2.98478105e-03, -1.37414271e-02, -4.60391417e-02, -2.84948312e-02,\n",
       "        1.60047673e-02,  2.35650167e-02,  6.51678741e-02, -1.34414211e-01,\n",
       "        5.32503575e-02,  3.56575884e-02, -7.86197372e-03,  9.42580476e-02,\n",
       "        7.51021355e-02, -4.59112935e-02, -2.59062573e-02, -8.13661423e-03,\n",
       "       -4.72550467e-02, -1.31417215e-02,  2.04975810e-03,  1.18029192e-01,\n",
       "       -6.47227466e-02, -3.47120352e-02,  8.09305236e-02, -6.47075986e-03,\n",
       "       -7.83779100e-03,  7.27231354e-02,  7.74614920e-04, -2.91393884e-02,\n",
       "       -4.09572497e-02,  3.64904143e-02,  5.19580469e-02, -1.21849624e-03,\n",
       "        7.59603530e-02,  1.21100631e-03, -6.46290183e-02,  4.95601669e-02,\n",
       "        1.14616863e-02,  1.74823273e-02, -1.34857371e-01,  4.06713551e-03,\n",
       "        5.28545566e-02,  1.38003146e-02, -2.33475678e-02, -3.36047783e-02,\n",
       "       -4.76837456e-02, -5.87946288e-02,  7.93527290e-02,  2.63917409e-02,\n",
       "        8.06437526e-03, -3.62649448e-02,  7.79532269e-02,  2.94449385e-02,\n",
       "        1.38530573e-02, -6.79790750e-02,  3.65148224e-02,  4.71364446e-02,\n",
       "        5.82256615e-02,  2.37946324e-02, -2.13515330e-02,  6.09258227e-02,\n",
       "       -6.34692051e-03,  4.83583212e-02, -2.96827443e-02,  7.53657818e-02,\n",
       "       -1.11324061e-02, -6.52947463e-03, -1.12031875e-02,  4.23941016e-02,\n",
       "        6.75177760e-03, -3.16488184e-02, -1.12316877e-01,  4.42777164e-02,\n",
       "       -4.04832959e-02,  5.60898110e-02, -5.48602343e-02, -3.50935794e-02,\n",
       "        6.15438521e-02, -4.55538593e-02, -2.22456418e-02,  5.23733683e-02,\n",
       "        4.69227368e-03, -8.88966173e-02, -3.62850144e-03,  1.84216239e-02,\n",
       "       -2.28967778e-02, -7.06041530e-02, -2.25385814e-03,  2.31272858e-02,\n",
       "        2.94607505e-02,  2.25650165e-02,  2.47537307e-02, -3.41035111e-08,\n",
       "       -7.40527222e-03, -4.57421727e-02, -5.94552560e-03,  2.23693321e-03,\n",
       "        5.23922108e-02, -6.32356629e-02, -1.49257090e-02, -1.90043524e-02,\n",
       "        1.09723359e-02,  1.17130846e-01, -2.75038257e-02,  2.75767269e-03,\n",
       "       -1.70142599e-03,  4.72035892e-02,  3.81305926e-02,  1.45642594e-01,\n",
       "        2.27466244e-02,  4.55298796e-02,  3.74998897e-02, -2.74840323e-03,\n",
       "        9.44324136e-02, -7.13555142e-03, -6.40580952e-02,  2.42663715e-02,\n",
       "       -7.23637044e-02,  7.78560340e-02,  2.33158953e-02,  5.11148199e-02,\n",
       "        7.40769580e-02, -1.05746210e-01, -6.01440016e-03, -8.14577041e-04,\n",
       "       -1.19026499e-02,  1.43340984e-02,  1.21036719e-03,  7.32009634e-02,\n",
       "        1.93813685e-02, -6.47292957e-02, -7.16724545e-02,  5.43806814e-02,\n",
       "       -2.58815419e-02, -7.69409314e-02,  7.27361441e-02,  2.49488875e-02,\n",
       "        3.51078659e-02, -4.00204957e-02,  3.94962542e-03,  3.15111689e-02,\n",
       "        4.70005199e-02, -2.79238801e-02, -4.80674393e-02,  2.14306694e-02,\n",
       "       -1.26927532e-03,  2.07611509e-02,  7.66460672e-02,  3.87392789e-02,\n",
       "       -1.26683787e-02,  2.12908722e-02, -2.02831440e-02, -1.88021106e-03,\n",
       "        4.32769693e-02,  3.36659476e-02,  4.01977003e-02, -1.43965766e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "encoder.encode(\"Ala zostawiła kota w domu, bo uczy się korzystać z wektorowych baz danych.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9ea0a-e2fe-4140-acf5-36afdd4bb9ed",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "\n",
    "Twoim zadaniem jest dostarczenie możliwości wyszukiwania tekstów w wektorowej bazie danych.\n",
    "\n",
    "1. Zapoznaj się z plikiem `movies.json`. Zawiera on dane testowe zawierające listę filmów wraz z krótkim opisem fabuły z repozytorium [erik-sytnyk/movies-list](https://github.com/erik-sytnyk/movies-list/blob/master/db.json).\n",
    "2. Połącz się z Twoją instancją Qdrant.\n",
    "3. Stwórz kolekcję, która przechowa wektory tekstów (w tym przypadku dobrą odległością będzie `COSINE`, bo podobne teksty układają się w *podobną stronę* w przestrzeni.\n",
    "4. Wczytaj dane testowe, zwektoryzuj je i zapisz je w bazie danych.\n",
    "5. Napisz funkcję, która na podstawie zadanej frazy zwróci pasujące filmy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57f73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2bfa197-fa88-4721-90ab-31aebe142412",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movies.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "movies = data[\"movies\"]\n",
    "\n",
    "\n",
    "formatted_movies = [\n",
    "    {\n",
    "        \"id\": movie.get(\"id\", \"Unknown\"),\n",
    "        \"title\": movie.get(\"title\", \"Unknown\"),    \n",
    "        \"year\": movie.get(\"year\", \"Unknown\"),            \n",
    "        \"description\": movie.get(\"plot\", \"No plot\"),\n",
    "        \"director\": movie.get(\"director\", \"No plot\"),\n",
    "        \"actors\": movie.get(\"actors\", \"No plot\")      \n",
    "    }\n",
    "    for movie in movies\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd707f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://e15a0be7-90ca-491a-8bbb-ce2eae999b65.eu-west-2-0.aws.cloud.qdrant.io\", \n",
    "    api_key=\"zQM1p21iOtdl60K2LiXMDwxtofTP3zXZxxmZsJGaGi1GWBF8VcFLlQ\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3510950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7588/2253443379.py:11: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "combined_data = [\n",
    "    f\"{movie['title']}: {movie['director']}: {movie['description']}\" \n",
    "    for movie in formatted_movies\n",
    "]\n",
    "\n",
    "title = [movie[\"title\"] for movie in formatted_movies]\n",
    "vectors = encoder.encode(combined_data)\n",
    "\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=\"movies\",\n",
    "    vectors_config=VectorParams(size=len(vectors[0]), distance=Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cd723ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_db = [\n",
    "    {\n",
    "        \"id\": movie[\"id\"],                \n",
    "        \"vector\": vector,                 \n",
    "        \"payload\": {                      \n",
    "            \"title\": movie[\"title\"],\n",
    "            \"year\": movie[\"year\"],\n",
    "            \"description\": movie[\"description\"],\n",
    "            \"director\": movie[\"director\"],\n",
    "            \"actors\": movie[\"actors\"]\n",
    "        }\n",
    "    }\n",
    "    for movie, vector in zip(formatted_movies, vectors)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfd8dfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.upsert(\n",
    "    collection_name=\"movies\",\n",
    "    points=movies_db\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "273d3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "def search_movies(query: str, top_k: int = 5):\n",
    "\n",
    "\n",
    "    query_vector = encoder.encode([query])[0]\n",
    "\n",
    "    results = qdrant_client.search(\n",
    "        collection_name=\"movies\",\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k \n",
    "    )\n",
    "\n",
    "    movies = [\n",
    "        {\n",
    "            \"title\": result.payload[\"title\"],\n",
    "            \"year\": result.payload[\"year\"],\n",
    "            \"description\": result.payload[\"description\"],\n",
    "            \"director\": result.payload[\"director\"],\n",
    "            \"actors\": result.payload[\"actors\"]\n",
    "        }\n",
    "        for result in results\n",
    "    ]\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7da5c603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7588/3881572148.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = qdrant_client.search(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Alice in Wonderland',\n",
       "  'year': '2010',\n",
       "  'description': \"Nineteen-year-old Alice returns to the magical world from her childhood adventure, where she reunites with her old friends and learns of her true destiny: to end the Red Queen's reign of terror.\",\n",
       "  'director': 'Tim Burton',\n",
       "  'actors': 'Johnny Depp, Mia Wasikowska, Helena Bonham Carter, Anne Hathaway'},\n",
       " {'title': 'Beetlejuice',\n",
       "  'year': '1988',\n",
       "  'description': 'A couple of recently deceased ghosts contract the services of a \"bio-exorcist\" in order to remove the obnoxious new owners of their house.',\n",
       "  'director': 'Tim Burton',\n",
       "  'actors': 'Alec Baldwin, Geena Davis, Annie McEnroe, Maurice Page'},\n",
       " {'title': 'Corpse Bride',\n",
       "  'year': '2005',\n",
       "  'description': 'When a shy groom practices his wedding vows in the inadvertent presence of a deceased young woman, she rises from the grave assuming he has married her.',\n",
       "  'director': 'Tim Burton, Mike Johnson',\n",
       "  'actors': 'Johnny Depp, Helena Bonham Carter, Emily Watson, Tracey Ullman'},\n",
       " {'title': 'Gran Torino',\n",
       "  'year': '2008',\n",
       "  'description': \"Disgruntled Korean War veteran Walt Kowalski sets out to reform his neighbor, a Hmong teenager who tried to steal Kowalski's prized possession: a 1972 Gran Torino.\",\n",
       "  'director': 'Clint Eastwood',\n",
       "  'actors': 'Clint Eastwood, Christopher Carley, Bee Vang, Ahney Her'},\n",
       " {'title': 'Crocodile Dundee',\n",
       "  'year': '1986',\n",
       "  'description': 'An American reporter goes to the Australian outback to meet an eccentric crocodile poacher and invites him to New York City.',\n",
       "  'director': 'Peter Faiman',\n",
       "  'actors': 'Paul Hogan, Linda Kozlowski, John Meillon, David Gulpilil'},\n",
       " {'title': 'Gandhi',\n",
       "  'year': '1982',\n",
       "  'description': \"Gandhi's character is fully explained as a man of nonviolence. Through his patience, he is able to drive the British out of the subcontinent. And the stubborn nature of Jinnah and his commitment towards Pakistan is portrayed.\",\n",
       "  'director': 'Richard Attenborough',\n",
       "  'actors': 'Ben Kingsley, Candice Bergen, Edward Fox, John Gielgud'},\n",
       " {'title': 'Troy',\n",
       "  'year': '2004',\n",
       "  'description': \"An adaptation of Homer's great epic, the film follows the assault on Troy by the united Greek forces and chronicles the fates of the men involved.\",\n",
       "  'director': 'Wolfgang Petersen',\n",
       "  'actors': 'Julian Glover, Brian Cox, Nathan Jones, Adoni Maropis'},\n",
       " {'title': 'The Big Short',\n",
       "  'year': '2015',\n",
       "  'description': 'Four denizens in the world of high-finance predict the credit and housing bubble collapse of the mid-2000s, and decide to take on the big banks for their greed and lack of foresight.',\n",
       "  'director': 'Adam McKay',\n",
       "  'actors': 'Ryan Gosling, Rudy Eisenzopf, Casey Groves, Charlie Talbert'},\n",
       " {'title': 'Nebraska',\n",
       "  'year': '2013',\n",
       "  'description': 'An aging, booze-addled father makes the trip from Montana to Nebraska with his estranged son in order to claim a million-dollar Mega Sweepstakes Marketing prize.',\n",
       "  'director': 'Alexander Payne',\n",
       "  'actors': 'Bruce Dern, Will Forte, June Squibb, Bob Odenkirk'},\n",
       " {'title': 'American Gangster',\n",
       "  'year': '2007',\n",
       "  'description': 'In 1970s America, a detective works to bring down the drug empire of Frank Lucas, a heroin kingpin from Manhattan, who is smuggling the drug into the country from the Far East.',\n",
       "  'director': 'Ridley Scott',\n",
       "  'actors': 'Denzel Washington, Russell Crowe, Chiwetel Ejiofor, Josh Brolin'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_movies(\"Tim Burton\", 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
